import os
import json
import logging
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# Configura√ß√£o inicial
load_dotenv()  # Carrega vari√°veis do .env

# Verifica√ß√£o cr√≠tica das vari√°veis
if not os.getenv("OPENAI_API_KEY"):
    raise RuntimeError("Chave OpenAI n√£o encontrada no arquivo .env")

# Configura√ß√£o de pastas
Path("dados").mkdir(exist_ok=True)
Path("uploads").mkdir(exist_ok=True)

# Configura√ß√£o de logging
logging.basicConfig(
    level=os.getenv("LOG_LEVEL", "INFO"),
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('oraculo.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BancoDeDados:
    # ... (mantenha igual ao c√≥digo anterior) ...
    # M√©todos: carregar_dados, salvar_dados, adicionar_pergunta, responder_pergunta

class GerenciadorIA:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.config = {
            "model": os.getenv("MODEL_IA", "gpt-4-turbo"),
            "temperature": float(os.getenv("TEMPERATURA", 0.7)),
            "max_tokens": int(os.getenv("MAX_TOKENS", 350))
        }

    def gerar_resposta(self, pergunta):
        try:
            response = self.client.chat.completions.create(
                model=self.config["model"],
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um or√°culo ancestral. Forne√ßa insights profundos em 3 partes: 1) Verdade universal 2) Conselho pr√°tico 3) Met√°fora"
                    },
                    {
                        "role": "user",
                        "content": pergunta
                    }
                ],
                temperature=self.config["temperature"],
                max_tokens=self.config["max_tokens"]
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Erro na IA: {str(e)}")
            return "üîÆ [O or√°culo est√° em sil√™ncio hoje]"

class Oraculo:
    # ... (mantenha a mesma estrutura da vers√£o anterior) ...
    # M√©todos: processar_pergunta, _salvar_arquivo, listar_perguntas

# Interface de linha de comando
if __name__ == "__main__":
    try:
        print("\n=== OR√ÅCULO S√ÅBIO ===")
        print(f"Modelo: {os.getenv('MODEL_IA')}")
        print("----------------------")
        
        oraculo = Oraculo()
        
        while True:
            print("\n1. Fazer pergunta\n2. Ver hist√≥rico\n3. Sair")
            opcao = input("Escolha: ").strip()
            
            if opcao == "1":
                pergunta = input("\nSua pergunta: ").strip()
                if pergunta:
                    resultado = oraculo.processar_pergunta(pergunta)
                    print(f"\nüí° Resposta:\n{resultado['resposta']}")
                else:
                    print("Por favor, digite uma pergunta v√°lida.")
            
            elif opcao == "2":
                print("\nüìú Hist√≥rico:")
                for p in oraculo.listar_perguntas(respondidas=True):
                    print(f"\nID {p['id']} - {p['data']}")
                    print(f"Pergunta: {p['pergunta']}")
                    print(f"Resposta: {p['resposta']}")
            
            elif opcao == "3":
                print("\nAt√© a pr√≥xima busca por sabedoria!")
                break
            
            else:
                print("Op√ß√£o inv√°lida. Tente 1, 2 ou 3.")
    
    except Exception as e:
        logger.critical(f"Falha cr√≠tica: {str(e)}")
        print("O or√°culo encontrou um erro. Verifique os logs.")
